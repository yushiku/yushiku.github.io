<!DOCTYPE html>
<html>
<head>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-125103456-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-125103456-1');
</script>
<meta charset="UTF8">
<link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="ushiku.css">
<link rel="shortcut icon" href="/assets/favicon.ico" type="image/vnd.microsoft.icon"/>
<link rel="icon" href="/assets/favicon.ico" type="image/vnd.microsoft.icon"/>
<title>Yoshitaka Ushiku's homepage</title>
</head>
<body>

<div>English/<a href="index_ja.html">Japanese</a></div>

<h1>Yoshitaka Ushiku</h1>

<div>
<img src="ushiku.jpg" style="width: 540px; max-width: 50%; height: auto;">
</div>

<h2>Talk Slides</h2>
<h3>Keynotes</h3>
<iframe src="//www.slideshare.net/slideshow/embed_code/key/thoD2I4GyhT4he" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/YoshitakaUshiku/frontiers-of-vision-and-language-bridging-images-and-texts-by-deep-learning-81870137" title="Frontiers of Vision and Language: Bridging Images and Texts by Deep Learning" target="_blank">Frontiers of Vision and Language: Bridging Images and Texts by Deep Learning</a> </strong> from <strong><a href="https://www.slideshare.net/YoshitakaUshiku" target="_blank">Yoshitaka Ushiku</a></strong> </div>

<h2>Education</h2>
<dl>
<dt>2009</dt>
<dd>BS of Engineering (The Univeresity of Tokyo)</dd>
<dt>2011</dt>
<dd>MA of Information Science and Technology (The University of Tokyo)</dd>
<dt>2014</dt>
<dd>Ph.D. (The University of Tokyo)</dd>
</dl>

<h2>Profession</h2>
<dl>
<dt>Apr. 2013 - Mar. 2014</dt>
<dd>Research Fellow, Japan Society for Promotion of Science</dd>
<dt>June 2013 - Aug. 2013</dt>
<dd>Intern, Microsoft Research Redmond</dd>
<dt>Apr. 2014 - Mar. 2016</dt>
<dd>Research Scientist, NTT Communication Science Laboratories.</dd>
<dt>Apr. 2016 - Sep. 2018</dt>
<dd>Associate Professor, Department of Mechano-Informatics, Graduate School of Information Science and Technology, the University of Tokyo</dd>
<dt>June 2016 - </dt>
<dd><span class="mention">Visiting Researcher, National Institute of Advanced Industrial Science and Technology (AIST)</span></dd>
<dt>Sep. 2016 - Sep. 2018</dt>
<dd>Collaborative Researcher, National Institute for Japanese Language and Linguistics (NINJAL)</dd>
<dt>Apr. 2018 - Sep. 2018</dt>
<dd>Technical Advisor, OMRON SINIC X Corporation (OSX)</dd>
<dt>Oct. 2018 - </dt>
<dd><span class="mention">Principal Investigator, OMRON SINIC X Corporation (OSX)</span></dd>
<dt>Jan. 2019 - Oct. 2020</dt>
<dd>Chief Research Officer, Ridge-i Co., Ltd.</dd>
<dt>Apr. 2020 - </dt>
<dd><span class="mention">Lecturer (part-time), Tsuda University</span></dd>
<dt>Nov. 2020 - </dt>
<dd><span class="mention">Director, Chief Research Officer, Ridge-i Co., Ltd.</span></dd>
<dt>July 2021 - </dt>
<dd><span class="mention">Lecturer (part-time), Tohoku University</span></dd>
</dl>

<h2>Activity</h2>

<h3>Society</h3>
<dl>
<dt>June 2018</dt>
<dd>International Conference on Multimedia Retrieval (ICMR) Publication Co-chairs</dd>
<dt>October 2019</dt>
<dd>International Conference on Computer Vision (ICCV) Workshop on Multi-Discipline Approach for Learning Concepts--Zero-Shot, One-Shot, Few-Shot and Beyond-- Organizer</dd>
<dt>November 2020</dt>
<dd>Asian Conference on Computer Vision (ACCV) Area Chair</dd>
<dt>December 2022</dt>
<dd>Asian Conference on Computer Vision (ACCV) Industrial Chair</dd>
<dt>

<h3>Reviewer</h3>
<dl>
<dt>Conference</dt>
<dd>
<span class="conf">AAAI 2020</span>, 
<span class="conf">ACMMM 2013 2016 2018 2019</span>, 
<span class="conf">ACPR 2017</span>, 
<span class="conf">BMVC 2020</span>, 
<span class="conf">CVPR 2019 2020 2021 2022</span>, 
<span class="conf">ECCV 2020 2022</span>, 
<span class="conf">ICCV 2019 2021</span>, 
<span class="conf">ICLR 2020 2021 2022</span>, 
<span class="conf">ICML 2021 2022</span>, 
<span class="conf">IJCAI 2018 2019</span>, 
<span class="conf">NeurIPS 2020 2021</span>, 
<span class="conf">PCM 2018</span>
</dd>
<dt>Journal</dt>
<dd>
<span class="journal">Advanced Robotics</span>, 
<span class="journal">Computer Speech and Language</span>, 
<span class="journal">IEEE Access</span>, 
<span class="journal">International Journal of Computer Vision</span>, 
<span class="journal">Neural Networks</span>, 
<span class="journal">Pattern Recognition Letters</span>, 
<span class="journal">Robotics and Automation Letters</span>, 
<span class="journal">Speech and Language Processing</span>, 
<span class="journal">The Visual Computer</span>
<span class="journal">Transactions on Affective Computing</span>, 
<span class="journal">Transactions on Audio</span>, 
<span class="journal">Transactions on Computer Vision and Applications</span>, 
<span class="journal">Transactions on Intelligent Systems and Technology</span>,
<span class="journal">Transactions on Multimedia</span>, 
<span class="journal">Transactions on Multimedia Computing, Communications, and Applications</span>, 
<span class="journal">Transactions on Pattern Analysis and Machine Intelligence</span>, 
<span class="journal">Transactions on Systems, Man and Cybernetics: Systems</span>.
</dd>
</dl>  

</dl>

<h2>Biography</h2>
<p>
Yoshitaka Ushiku is a Principal Investigator at OMRON SINIC X and Chief Research Officer at Ridge-i.
He received his B.E., M.A., and Ph.D. degrees from the University of Tokyo in 2009, 2011, and 2014, respectively.
In 2014, he joined NTT CS Labs, Japan, where he was involved in research on image recognition.
From 2016 to 2018, he was an Associate Professor at the University of Tokyo, Japan.
Currently, he is a Principal Investigator at OMRON SINIC X and Chief Research Officer at Ridge-i since 2018 and 2019, respectively.
Since 2022, he is also the managing partner of Nine Bulls, LLC.
His research interests lie in cross-media understanding through machine learning, mainly for computer vision and natural language processing.
He received ACM Mutlimedia Grand Challenge Special Prize in 2011, ACM Multimedia Open Source Software Competition Honorable Mention in 2017, and NVIDIA Pioneering Research Awards in 2017 and 2018.
</p>

<h2>Contact</h2>
<div>
<img src="mailaddr.png" width="427" height="32">
<a href="http://www.twitter.com/losnuevetoros"><img src="tw.png" width="32" height="32"></a>
<a href="http://www.facebook.com/yoshitaka.ushiku"><img src="fb.png" width="32" height="32"></a>
<a href="https://www.linkedin.com/in/losnuevetoros"><img src="li.png" width="38.4" height="32"></a>
<a href="http://www.slideshare.net/YoshitakaUshiku"><img src="ss.png" width="70.4" height="32"></a>
<a href="https://speakerdeck.com/yushiku"><img src="sd.png" width="32" height="32"></a>
<a href="https://scholar.google.co.jp/citations?user=kxUld9MAAAAJ&hl=ja"><img src="gs.png" width="32" height="32"></a>
<a href="https://orcid.org/0000-0002-9014-1389"><img src="oi.png" width="32" height="32"></a>
</div>

<h2>Papers</h2>
<h3>Journal (refereed)</h3>
<ol>
<li>Takehiko Ohkawa, Takuma Yagi, Atsushi Hashimoto, Yoshitaka Ushiku, and Yoichi Sato. Foreground-Aware Stylization and Consensus Pseudo-Labeling for Domain Adaptation of First-Person Hand Segmentation. <span class="journal">IEEE Access</span>, Vol.9, pp.94644-94655, 2021.</li>
<li>Taichi Nishimura, Atsushi Hashimoto, Yoshitaka Ushiku, Hirotaka Kameko, Yoko Yamakata, and Shinsuke Mori. Structure-Aware Procedural Text Generation From an Image Sequence. <span class="journal">IEEE Access</span>, Vol.9, pp.2125-2141, 2021.</li>
<li>Hiroaki Minoura, Ryo Yonetani, Mai Nishimura, and Yoshitaka Ushiku. Crowd Density Forecasting by Modeling Patch-Based Dynamics. <span class="journal">IEEE Robotics and Automation Letters</span>, Vol.6, No.2, pp.287-294, 2021.</li>
<li>Yusuke Mori, Hiroaki Yamane, Yoshitaka Ushiku, and Tatsuya Harada. How narratives move your mind: A corpus of shared-character stories for connecting emotional flow and interestingness. <span class="journal">Information Processing &amp; Management</span>, Vol.56, No.5, pp.1865-1879, 2019.</li>
</ol>
<h3>International Conference (refereed)</h3>
<ol>
<li>Taichi Nishimura, Atsushi Hashimoto, Yoshitaka Ushiku, Hirotaka Kameko, and Shinsuke Mori. State-aware Video Procedural Captioning. ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), 2021.</li>
<li>Mutsuki Nakahara, Daisuke Hisano, Mai Nishimura, Yoshitaka Ushiku, Kazuki Maruta, and Yu Nakayama. Retransmission Edge Computing System Conducting Adaptive Image Compression Based on Image Recognition Accuracy. IEEE Vehicular Technology Conference (<span class="conf">VTC-Fall</span>), 2021. </li>
<li>Qing Yu, Atsushi Hashimoto, and Yoshitaka Ushiku. Divergence Optimization for Noisy Universal Domain Adaptation. The IEEE Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2021.</li>
<li>Ukyo Honda, Yoshitaka Ushiku, Atsushi Hashimoto, Taro Watanabe, and Yuji Matsumoto. Removing Word-Level Spurious Alignment between Images and Pseudo-Captions in Unsupervised Image Captioning. The Conference of the European Chapter of the Association for Computational Linguistics (<span class="conf">EACL</span>), 2021.</li>
<li>Taichi Nishimura, Suzushi Tomori, Hayato Hashimoto, Atsushi Hashimoto, Yoko Yamakata, Jun Harashima, Yoshitaka Ushiku, and Shinsuke Mori. Visual Grounding Annotation of Recipe Flow Graph. Language Resources and Evaluation Conference (<span class="conf">LREC</span>), 2020.</li>
<li>Takuhiro Kaneko, Yoshitaka Ushiku, and Tatsuya Harada. Class-distinct and class-mutual image generation with GANs. British Machine Vision Conference (<span class="conf">BMVC</span>), 2019.</li>
<li>Mikihiro Tanaka, Takayuki Itamochi, Kenichi Narioka, Ikuro Sato, Yoshitaka Ushiku, and Tatsuya Harada. Generating Easy-to-Understand Referring Expressions for Target Identifications. The IEEE International Conference on Computer Vision (<span class="conf">ICCV</span>),	2019.
<li>Takuhiro Kaneko, Yoshitaka Ushiku, and Tatsuya Harada. Label-noise robust generative adversarial networks. The IEEE Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2019.</li>
<li>Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, and Kate Saenko. Strong-weak distribution alignment for adaptive object detection. The IEEE Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2019</li>
<li>Yang Li, Yoshitaka Ushiku, and Tatsuya Harada. Pose Graph Optimization for Unsupervised Monocular Visual Odometry. International Conference on Robotics and Automation (<span class="conf">ICRA</span>), 2019.</li>
<li>Akane Iseki, Yusuke Mukuta, Yoshitaka Ushiku, and Tatsuya Harada. Estimating the causal effect from partially observed time series. The AAAI Conference on Artificial Intelligence (<span class="conf">AAAI</span>), 2019.</li>
<li>Kohei Uehara, Antonio Tejero-de-Pablos, Yoshitaka Ushiku, Tatsuya Harada. Visual Question Generation for Class Acquisition of Unknown Objects. The 15th European Conference on Computer Vision (<span class="conf">ECCV</span>), 2018.</li>
<li>Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, Tatsuya Harada. Open Set Domain Adaptation by Backpropagation. The 15th European Conference on Computer Vision (<span class="conf">ECCV</span>), 2018.</li>
<li>Andrew Shin, Yoshitaka Ushiku, Tatsuya Harada. Customized Image Narrative Generation via Interactive Visual Question Generation and Answering. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018. (spotlight presentation)</li>
<li>Atsushi Kanehira, Luc Van Gool, Yoshitaka Ushiku, Tatsuya Harada. Viewpoint-aware Video Summarization. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018. (spotlight presentation)</li>
<li>Hiroharu Kato, Yoshitaka Ushiku, Tatsuya Harada. Neural 3D Mesh Renderer. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018. (spotlight presentation)</li>
<li>Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, Tatsuya Harada. Maximum Classifier Discrepancy for Unsupervised Domain Adaptation. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018. (oral presentation)</li>
<li>Yuji Tokozume, Yoshitaka Ushiku, Tatsuya Harada. Between-class Learning for Image Classification. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018..</li>
<li>Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, Kate Saenko. Adversarial Dropout Regularization. The 6th International Conference on Learning Representations (<span class="conf">ICLR</span>), 2018.</li>
<li>Yuji Tokozume, Yoshitaka Ushiku, Tatsuya Harada. Learning from Between-class Examples for Deep Sound Recognition. The 6th International Conference on Learning Representations (<span class="conf">ICLR</span>), 2018.</li>
<li>Katsunori Ohnishi, Shohei Yamamoto, Yoshitaka Ushiku, Tatsuya Harada. Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture. AAAI Conference on Artificial Intelligence (<span class="conf">AAAI</span>), 2018. (oral presentation)</li>
<li>Yusuke Mukuta, Yoshitaka Ushiku, Tatsuya Harada. Alternating Circulant Random Features for Semigroup Kernels. AAAI Conference on Artificial Intelligence (<span class="conf">AAAI</span>), 2018.</li>
<li>Masatoshi Hidaka, Yuichiro Kikura, Yoshitaka Ushiku, Tatsuya Harada. WebDNN: Fastest DNN Execution Framework on Web Browser. ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), Open Source Software Competition, pp.1213-1216, 2017.</li>
<li>Masataka Yamaguchi, Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada. Spatio-temporal Person Retrieval via Natural Language Queries. IEEE International Conference on Computer Vision (<span class="conf">ICCV</span>), 2017.</li>
<li>Qishen Ha, Kohei Watanabe, Takumi Karasawa, Yoshitaka Ushiku, Tatsuya Harada. MFNet: Towards Real-Time Semantic Segmentation for Autonomous Vehicles with Multi-Spectral Scenes. IEEE/RSJ International Conference on Intelligent Robots and Systems (<span class="conf">IROS</span>), 2017.</li>
<li>Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. Asymmetric Tri-training for Unsupervised Domain Adaptation. International Conference on Machine Learning (<span class="conf">ICML</span>), pp.2988-2997, 2017.</li>
<li>Kuniaki Saito, Andrew Shin, Yoshitaka Ushiku, and Tatsuya Harada. DualNet: Domain-Invariant Network for Visual Question Answering. IEEE International Conference on Multimedia and Expo (<span class="conf">ICME</span>), pp.829-834, 2017. (oral presentation)</li>
<li>Andrew Shin, Yoshitaka Ushiku, and Tatsuya Harada. Image Captioning with Sentiment Terms via Weakly-Supervised Sentiment Dataset. British Machine Vision Conference (<span class="conf">BMVC</span>), pp.53.1-53.12, 2016.</li>
<li>Yoshitaka Ushiku, Masataka Yamaguchi, Yusuke Mukuta, and Tatsuya Harada. Common subspace for model and similarity: Phrase learning for caption generation from images. IEEE International Conference on Computer Vision (<span class="conf">ICCV</span>), pp.2668-2676, 2015. (acceptance rate: 30.9%)</li>
<li>Yoshitaka Ushiku, Masatoshi Hidaka, and Tatsuya Harada. Three guidelines of online learning for large-scale visual recognition. IEEE Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), pp.3574-3581, 2014. (acceptance rate: 29.9%)</li>
<li>Asako Kanezaki, Shogo Inaba, Yoshitaka Ushiku, Yukihiko Yamashita, Hiroaki Muraoka, Yasuo Kuniyoshi, and Tatsuya Harada. Hard negative classes for multiple object detection. IEEE International Conference on Robotics and Automation (<span class="conf">ICRA</span>), pp.3066-3073, 2014.</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Efficient Image Annotation for Automatic Sentence Generation. ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), pp.549-558, 2012. (full paper, acceptance rate: 20.2%)</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Understanding Images with Natural Sentences. ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), Multimedia Grand Challenge, pp.679-682, 2011. (<span class="mention">Special Prize on the Best Application of a Theoretical Framework</span>) [<a href="http://www.isi.imi.i.u-tokyo.ac.jp/publication/2011/ACMMM2011_MGC_ushiku.pdf">pdf</a>]</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Automatic Sentence Generation from Images. ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), pp.1533-1536, 2011. (short, acceptance rate: usually 30%) [<a href="http://www.isi.imi.i.u-tokyo.ac.jp/publication/2011/ACMMM2011_ushiku.pdf">pdf</a>]</li>
<li>Tatsuya Harada, Yoshitaka Ushiku, Yuya Yamashita, and Yasuo Kuniyoshi. Discriminative Spatial Pyramid. IEEE Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), pp.1617-1624, 2011. (acceptance rate: 26.4%) [<a href="http://www.isi.imi.i.u-tokyo.ac.jp/publication/2011/CVPR2011_harada.pdf">pdf</a>]</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Improvement of Image Similarity Measures for Image Browsing and Retrieval Via Latent Space Learning between Images and Long Texts. IEEE International Conference on Image Processing (<span class="conf">ICIP</span>), pp.2365-2368, 2010. [<a href="http://www.isi.imi.i.u-tokyo.ac.jp/publication/2010/ICIP2010_ushiku.pdf">pdf</a>]</li>
</ol>
<h3>International Conference (unrefereed or workshop)</h3>
<ol>
<li>Kuniaki Saito, Yusuke Mukuta, Yoshitaka Ushiku, Tatsuya Harada. Deep Modality Invariant Adversarial Network for Shared Representation Learning. The 16th International Conference on Computer Vision Workshop on Transferring and Adapting Source Knowledge in Computer Vision (<span class="conf">ICCV</span>, Workshop), 2017.</li>
<li>Yusuke Mukuta, Yoshitaka Ushiku, Tatsuya Harada. Spatial-Temporal Weighted Pyramid using Spatial Orthogonal Pooling. The 16th International Conference on Computer Vision Workshop on Compact and Efficient Feature Representation and Learning in Computer Vision (<span class="conf">ICCV</span>, Workshop), 2017.</li>
<li>Takumi Karasawa, Kohei Watanabe, Qishen Ha, Antonio Tejero-De-Pablos, Yoshitaka Ushiku, Tatsuya Harada. Multispectral Object Detection for Autonomous Vehicles. The 25th Annual ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), 2017, (workshop).</li>
<li>Yoshitaka Ushiku, Hiroshi Muraoka, Sho Inaba, Teppei Fujisawa, Koki Yasumoto, Naoyuki Gunji, Takayuki Higuchi, Yuko Hara, Tatsuya Harada, and Yasuo Kuniyoshi. ISI at ImageCLEF 2012: Scalable System for Image Annotation. the 3rd Conference and Labs of the Evaluation Forum (<span class="conf">CLEF</span> 2012), pp.1-12, 2012.</li>
</ol>
<h3>Technical Report</h3>
<ol>
<li>Shoji Yamamoto, Antonio Tejero-de-Pablos, Yoshitaka Ushiku, and Tatsuya Harada. Conditional Video Generation Using Action-Appearance Captions. arXiv, 1812.01261, 2018.</li>
<li>Andrew Shin, Yoshitaka Ushiku, and Tatsuya Harada. The Color of the Cat is Gray: 1 Million Full-Sentences Visual Question Answering (FSVQA). arXiv, 1609.06657, 2016.</li>
</ol>

<h3>Domestic Journal (refereed, In Japanese)</h3>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic papers.
</p>
<h3>Domestic Conference (refereed, In Japanese)</h3>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic papers.
</p>
<h3>Domestic Conference (unrefereed, In Japanese)</h3>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic papers.
</p>

<h2>Books</h2>
<ol>
<li>Yoshitaka Ushiku. Long Short-Term Memory. In: Ikeuchi K. (eds) Computer Vision. Springer, 2020.</li>
</ol>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic books.
</p>
  
<h2>Invited Talks</h2>
<ol>
<li>Yoshitaka Ushiku. Towards a symbiosis between AI and humans: The State-of-the-art. Director General of Intellectual Property, online, Indonesia, 2022/01/13.</li>
<li>Yoshitaka Ushiku. Challenges of Integrating Vision and Language. International Display Workshops, online, Japan, 2021/12/01.</li>
<li>Yoshitaka Ushiku. Towards a symbiosis between AI and humans: The State-of-the-art. Intellectual Property Office of Vietnam, online, Vietnam, 2021/11/17.</li>
<li>Yoshitaka Ushiku. Multimodal Understanding: Vision and Language, and its Beyond. International Workshop on Frontiers of Computer Vision, Daegu, Korea, 2021/02/22.</li>
<li>Yoshitaka Ushiku. Deep Learning for Natural Language Processing and Computer Vision. Tutorial on Asian Conference on Machine Learning, Nagoya, Japan, 2019/11/17.</li>
<li>Yoshitaka Ushiku. Frontiers of Vision and Language: Bridging Images and Texts by Deep Learning. Workshop of Machine Learning under International Conference on Document Analysis and Recognition, Kyoto, Japan, 2017/11/11.</li>
<li>Yoshitaka Ushiku. Recognize, Describe, and Generate: Introduction of Recent Work at MIL. GPU Technology Conference, San Jose, CA, 2017/05/11.</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Efficient Image Annotation for Automatic Sentence Generation. Greater Tokyo Area Multimedia/Vision Workshop, Tokyo, Japan, 2012/08/30.</li>
</ol>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic talks.
</p>

<h2>Awards and Competitions</h2>
<ol>
<li>2018. <span class="award">NVIDIA Pioneering Research Awards</span> for Neural 3D Mesh Renderer.</li>
<li>2017. <span class="award">NVIDIA Pioneering Research Awards</span> for Asymmetric Tri-training for unsupervised domain adoptation.</li>
<li>2017. <span class="award">Honorable Mention</span>. ACM Multimedia Open Source Software Competition.</li>
<li>2016. <span class="award">First place</span> in the abstract image task. Visual Question Answering Challenge 2016.</li>
<li>2012. <span class="award">First place</span> in the fine-grained classification task, <span class="award">second place</span> in the classification task. Large Scale Visual Recognition Challenge 2012 (ILSVRC2012).</li>
<li>2011. <span class="award">Special Prize on the Best Application of a Theoretical Framework</span>. ACM Mutlimedia Grand Challenge.</li>
<li>2011. <span class="award">Third place</span> in the classification task, <span class="award">second place</span> in the detection task. Large Scale Visual Recognition Challenge 2011 (ILSVRC2011).</li>
<li>2010. <span class="award">Third place</span>. Large Scale Visual Recognition Challenge 2010 (ILSVRC2010).</li>
</ol>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic awards.
</p>

</body>
</html>
