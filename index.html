<!DOCTYPE html>
<html>
<head>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-125103456-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-125103456-1');
</script>
<meta charset="UTF8">
<link rel="stylesheet" href="style.css">
<link rel="stylesheet" href="ushiku.css">
<link rel="shortcut icon" href="/assets/favicon.ico" type="image/vnd.microsoft.icon"/>
<link rel="icon" href="/assets/favicon.ico" type="image/vnd.microsoft.icon"/>
<title>Yoshitaka Ushiku's homepage</title>
</head>
<body>

<div>English/<a href="index_ja.html">Japanese</a></div>

<h1>Yoshitaka Ushiku</h1>

<div>
<img src="ushiku.jpg" style="width: 540px; max-width: 50%; height: auto;">
</div>

<h2>Talk Slides</h2>
<h3>Keynotes</h3>
<iframe src="//www.slideshare.net/slideshow/embed_code/key/thoD2I4GyhT4he" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe> <div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/YoshitakaUshiku/frontiers-of-vision-and-language-bridging-images-and-texts-by-deep-learning-81870137" title="Frontiers of Vision and Language: Bridging Images and Texts by Deep Learning" target="_blank">Frontiers of Vision and Language: Bridging Images and Texts by Deep Learning</a> </strong> from <strong><a href="https://www.slideshare.net/YoshitakaUshiku" target="_blank">Yoshitaka Ushiku</a></strong> </div>

<h2>Education</h2>
<dl>
<dt>2009</dt>
<dd>BS of Engineering (The Univeresity of Tokyo)</dd>
<dt>2011</dt>
<dd>MA of Information Science and Technology (The University of Tokyo)</dd>
<dt>2014</dt>
<dd>Ph.D. (The University of Tokyo)</dd>
</dl>

<h2>Profession</h2>
<dl>
<dt>Apr. 2013 - Mar. 2014</dt>
<dd>Research Fellow, Japan Society for Promotion of Science</dd>
<dt>June 2013 - Aug. 2013</dt>
<dd>Intern, Microsoft Research Redmond</dd>
<dt>Apr. 2014 - Mar. 2016</dt>
<dd>Research Scientist, NTT Communication Science Laboratories.</dd>
<dt>Apr. 2016 - Sep. 2018</dt>
<dd>Lecturer, Department of Mechano-Informatics, Graduate School of Information Science and Technology, the University of Tokyo</dd>
<dt>June 2016 - </dt>
<dd>Visiting Researcher, National Institute of Advanced Industrial Science and Technology (AIST)</dd>
<dt>Sep. 2016 - Sep. 2018</dt>
<dd>Collaborative Researcher, National Institute for Japanese Language and Linguistics (NINJAL)</dd>
<dt>Apr. 2018 - Sep. 2018</dt>
<dd>Technical Advisor, OMRON SINIC X Corporation (OSX)</dd>
<dt>Oct. 2018 - </dt>
<dd>Principal Investigator, OMRON SINIC X Corporation (OSX)</dd>
</dl>

<h2>Society Activity</h2>
<dl>
<dt>June 2018</dt>
<dd>International Conference on Multimedia Retrieval (ICMR 2018) Publication Co-chairs</dd>
</dl>

<h2>Affiliation</h2>
<div>
OMRON SINIC X Corp.<br>
Research Administrative Division
</div>

<h2>Contact</h2>
<div>
<img src="mailaddr.png" width="323" height="30.5">
<a href="http://www.twitter.com/losnuevetoros"><img src="tw.png" width="32" height="32"></a>
<a href="http://www.facebook.com/yoshitaka.ushiku"><img src="fb.png" width="32" height="32"></a>
<a href="https://www.linkedin.com/in/losnuevetoros"><img src="li.png" width="38.4" height="32"></a>
<a href="http://www.slideshare.net/YoshitakaUshiku"><img src="ss.png" width="70.4" height="32"></a>
</div>

<h2>Papers</h2>
<h3>International Conference (refereed)</h3>
<ol>
<li>Kohei Uehara, Antonio Tejero-de-Pablos, Yoshitaka Ushiku, Tatsuya Harada. Visual Question Generation for Class Acquisition of Unknown Objects. The 15th European Conference on Computer Vision (<span class="conf">ECCV</span>), 2018.</li>
<li>Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, Tatsuya Harada. Open Set Domain Adaptation by Backpropagation. The 15th European Conference on Computer Vision (<span class="conf">ECCV</span>), 2018.</li>
<li>Andrew Shin, Yoshitaka Ushiku, Tatsuya Harada. Customized Image Narrative Generation via Interactive Visual Question Generation and Answering. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018. (spotlight presentation)</li>
<li>Atsushi Kanehira, Luc Van Gool, Yoshitaka Ushiku, Tatsuya Harada. Viewpoint-aware Video Summarization. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018. (spotlight presentation)</li>
<li>Hiroharu Kato, Yoshitaka Ushiku, Tatsuya Harada. Neural 3D Mesh Renderer. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018. (spotlight presentation)</li>
<li>Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, Tatsuya Harada. Maximum Classifier Discrepancy for Unsupervised Domain Adaptation. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018. (oral presentation)</li>
<li>Yuji Tokozume, Yoshitaka Ushiku, Tatsuya Harada. Between-class Learning for Image Classification. The 31th IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), 2018..</li>
<li>Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada, Kate Saenko. Adversarial Dropout Regularization. The 6th International Conference on Learning Representations (<span class="conf">ICLR</span>), 2018.</li>
<li>Yuji Tokozume, Yoshitaka Ushiku, Tatsuya Harada. Learning from Between-class Examples for Deep Sound Recognition. The 6th International Conference on Learning Representations (<span class="conf">ICLR</span>), 2018.</li>
<li>Katsunori Ohnishi, Shohei Yamamoto, Yoshitaka Ushiku, Tatsuya Harada. Hierarchical Video Generation from Orthogonal Information: Optical Flow and Texture. AAAI Conference on Artificial Intelligence (<span class="conf">AAAI</span>), 2018. (oral presentation)</li>
<li>Yusuke Mukuta, Yoshitaka Ushiku, Tatsuya Harada. Alternating Circulant Random Features for Semigroup Kernels. AAAI Conference on Artificial Intelligence (<span class="conf">AAAI</span>), 2018.</li>
<li>Masatoshi Hidaka, Yuichiro Kikura, Yoshitaka Ushiku, Tatsuya Harada. WebDNN: Fastest DNN Execution Framework on Web Browser. ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), Open Source Software Competition, pp.1213-1216, 2017.</li>
<li>Masataka Yamaguchi, Kuniaki Saito, Yoshitaka Ushiku, Tatsuya Harada. Spatio-temporal Person Retrieval via Natural Language Queries. IEEE International Conference on Computer Vision (<span class="conf">ICCV</span>), 2017.</li>
<li>Qishen Ha, Kohei Watanabe, Takumi Karasawa, Yoshitaka Ushiku, Tatsuya Harada. MFNet: Towards Real-Time Semantic Segmentation for Autonomous Vehicles with Multi-Spectral Scenes. IEEE/RSJ International Conference on Intelligent Robots and Systems (<span class="conf">IROS</span>), 2017.</li>
<li>Kuniaki Saito, Yoshitaka Ushiku, and Tatsuya Harada. Asymmetric Tri-training for Unsupervised Domain Adaptation. International Conference on Machine Learning (<span class="conf">ICML</span>), pp.2988-2997, 2017.</li>
<li>Kuniaki Saito, Andrew Shin, Yoshitaka Ushiku, and Tatsuya Harada. DualNet: Domain-Invariant Network for Visual Question Answering. IEEE International Conference on Multimedia and Expo (<span class="conf">ICME</span>), pp.829-834, 2017. (oral presentation)</li>
<li>Andrew Shin, Yoshitaka Ushiku, and Tatsuya Harada. Image Captioning with Sentiment Terms via Weakly-Supervised Sentiment Dataset. British Machine Vision Conference (<span class="conf">BMVC</span>), pp.53.1-53.12, 2016.</li>
<li>Yoshitaka Ushiku, Masataka Yamaguchi, Yusuke Mukuta, and Tatsuya Harada. Common subspace for model and similarity: Phrase learning for caption generation from images. IEEE International Conference on Computer Vision (<span class="conf">ICCV</span>), pp.2668-2676, 2015. (acceptance rate: 30.9%)</li>
<li>Yoshitaka Ushiku, Masatoshi Hidaka, and Tatsuya Harada. Three guidelines of online learning for large-scale visual recognition. IEEE Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), pp.3574-3581, 2014. (acceptance rate: 29.9%)</li>
<li>Asako Kanezaki, Shogo Inaba, Yoshitaka Ushiku, Yukihiko Yamashita, Hiroaki Muraoka, Yasuo Kuniyoshi, and Tatsuya Harada. Hard negative classes for multiple object detection. IEEE International Conference on Robotics and Automation (<span class="conf">ICRA</span>), pp.3066-3073, 2014.</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Efficient Image Annotation for Automatic Sentence Generation. ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), pp.549-558, 2012. (full paper, acceptance rate: 20.2%)</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Understanding Images with Natural Sentences. ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), Multimedia Grand Challenge, pp.679-682, 2011. (<span class="mention">Special Prize on the Best Application of a Theoretical Framework</span>) [<a href="http://www.isi.imi.i.u-tokyo.ac.jp/publication/2011/ACMMM2011_MGC_ushiku.pdf">pdf</a>]</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Automatic Sentence Generation from Images. ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), pp.1533-1536, 2011. (short, acceptance rate: usually 30%) [<a href="http://www.isi.imi.i.u-tokyo.ac.jp/publication/2011/ACMMM2011_ushiku.pdf">pdf</a>]</li>
<li>Tatsuya Harada, Yoshitaka Ushiku, Yuya Yamashita, and Yasuo Kuniyoshi. Discriminative Spatial Pyramid. IEEE Conference on Computer Vision and Pattern Recognition (<span class="conf">CVPR</span>), pp.1617-1624, 2011. (acceptance rate: 26.4%) [<a href="http://www.isi.imi.i.u-tokyo.ac.jp/publication/2011/CVPR2011_harada.pdf">pdf</a>]</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Improvement of Image Similarity Measures for Image Browsing and Retrieval Via Latent Space Learning between Images and Long Texts. IEEE International Conference on Image Processing (<span class="conf">ICIP</span>), pp.2365-2368, 2010. [<a href="http://www.isi.imi.i.u-tokyo.ac.jp/publication/2010/ICIP2010_ushiku.pdf">pdf</a>]</li>
</ol>
<h3>International Conference (unrefereed)</h3>
<ol>
<li>Yoshitaka Ushiku, Hiroshi Muraoka, Sho Inaba, Teppei Fujisawa, Koki Yasumoto, Naoyuki Gunji, Takayuki Higuchi, Yuko Hara, Tatsuya Harada, and Yasuo Kuniyoshi. ISI at ImageCLEF 2012: Scalable System for Image Annotation. the 3rd Conference and Labs of the Evaluation Forum (<span class="conf">CLEF</span> 2012), pp.1-12, 2012.</li>
</ol>
<h3>Technical Report</h3>
<ol>
<li>Kuniaki Saito, Yusuke Mukuta, Yoshitaka Ushiku, Tatsuya Harada. Deep Modality Invariant Adversarial Network for Shared Representation Learning. The 16th International Conference on Computer Vision Workshop on Transferring and Adapting Source Knowledge in Computer Vision (<span class="conf">ICCV</span>, Workshop), 2017.</li>
<li>Yusuke Mukuta, Yoshitaka Ushiku, Tatsuya Harada. Spatial-Temporal Weighted Pyramid using Spatial Orthogonal Pooling. The 16th International Conference on Computer Vision Workshop on Compact and Efficient Feature Representation and Learning in Computer Vision (<span class="conf">ICCV</span>, Workshop), 2017.</li>
<li>Takumi Karasawa, Kohei Watanabe, Qishen Ha, Antonio Tejero-De-Pablos, Yoshitaka Ushiku, Tatsuya Harada. Multispectral Object Detection for Autonomous Vehicles. The 25th Annual ACM International Conference on Multimedia (<span class="conf">ACMMM</span>), 2017, (workshop).</li>
<li>Yoshitaka Ushiku, Hiroshi Muraoka, Sho Inaba, Teppei Fujisawa, Koki Yasumoto, Naoyuki Gunji, Takayuki Higuchi, Yuko Hara, Tatsuya Harada, and Yasuo Kuniyoshi. ISI at ImageCLEF 2012: Scalable System for Image Annotation. the 3rd Conference and Labs of the Evaluation Forum (<span class="conf">CLEF</span> 2012), pp.1-12, 2012.</li>
</ol>

<h3>Domestic Journal (refereed, In Japanese)</h3>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic papers.
</p>
<h3>Domestic Conference (refereed, In Japanese)</h3>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic papers.
</p>
<h3>Domestic Conference (unrefereed, In Japanese)</h3>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic papers.
</p>

<h2>Invited Talks</h2>
<ol>
<li>Yoshitaka Ushiku. Frontiers of Vision and Language: Bridging Images and Texts by Deep Learning. Workshop of Machine Learning under International Conference on Document Analysis and Recognition, 2017/11/11.</li>
<li>Yoshitaka Ushiku. Recognize, Describe, and Generate: Introduction of Recent Work at MIL. GPU Technology Conference, 2017/05/11.</li>
<li>Yoshitaka Ushiku, Tatsuya Harada, and Yasuo Kuniyoshi. Efficient Image Annotation for Automatic Sentence Generation. Greater Tokyo Area Multimedia/Vision Workshop, 2012/08/30.</li>
</ol>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic talks.
</p>

<h2>Awards and Competitions</h2>
<ol>
<li>2017. <span class="award">Honorable Mention</span>. ACM Multimedia Open Source Software Competition.</li>
<li>2016. <span class="award">First place</span> in the abstract image task. Visual Question Answering Challenge 2016.</li>
<li>2012. <span class="award">First place</span> in the fine-grained classification task, <span class="award">second place</span> in the classification task. Large Scale Visual Recognition Challenge 2012 (ILSVRC2012).</li>
<li>2011. <span class="award">Special Prize on the Best Application of a Theoretical Framework</span>. ACM Mutlimedia Grand Challenge.</li>
<li>2011. <span class="award">Third place</span> in the classification task, <span class="award">second place</span> in the detection task. Large Scale Visual Recognition Challenge 2011 (ILSVRC2011).</li>
<li>2010. <span class="award">Third place</span>. Large Scale Visual Recognition Challenge 2010 (ILSVRC2010).</li>
</ol>
<p>
Go to <a href="index_ja.html">japanese page</a> for domestic awards.
</p>

</body>
</html>
